{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import numpy as np\n",
    "import optax\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from flax import linen\n",
    "from jax.lib import xla_bridge\n",
    "from turbanet import TurbaTrainState\n",
    "import altair as alt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL INPUTS\n",
    "GPU = False\n",
    "\n",
    "# NETWORK SHAPE INPUTS\n",
    "hidden_size = 10\n",
    "num_layers = 4\n",
    "\n",
    "# TRAINING INPUTS\n",
    "swarm_size = 10\n",
    "epochs = 10000\n",
    "lr = 1e-3\n",
    "dataset_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set numpy/torch/flax seeds\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random data\n",
    "def make_spirals(n_samples, noise_std=0.0, rotations=1.0):\n",
    "    ts = jnp.linspace(0, 1, n_samples)\n",
    "    rs = ts**0.5\n",
    "    thetas = rs * rotations * 2 * np.pi\n",
    "    signs = np.random.randint(0, 2, (n_samples,)) * 2 - 1\n",
    "    labels = (signs > 0).astype(int)\n",
    "\n",
    "    xs = rs * signs * jnp.cos(thetas) + np.random.randn(n_samples) * noise_std\n",
    "    ys = rs * signs * jnp.sin(thetas) + np.random.randn(n_samples) * noise_std\n",
    "    points = jnp.stack([xs, ys], axis=1)\n",
    "    return points, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_grid():\n",
    "    grid_size = 50\n",
    "    width = 1.5\n",
    "    x0s, x1s = jnp.meshgrid(\n",
    "        np.linspace(-width, width, grid_size), np.linspace(-width, width, grid_size)\n",
    "    )\n",
    "    xs = np.stack([x0s, x1s]).transpose().reshape((-1, 2))\n",
    "\n",
    "    return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_plot(xs, y):\n",
    "    df = pd.DataFrame({\"x\": xs[:, 0], \"y\": xs[:, 1], \"label\": y})\n",
    "\n",
    "    spirals_x_axis = alt.X(\"x\", scale=alt.Scale(domain=[-1.5, 1.5], nice=False))\n",
    "    spirals_y_axis = alt.Y(\"y\", scale=alt.Scale(domain=[-1.5, 1.5], nice=False))\n",
    "\n",
    "    spiral_chart = (\n",
    "        alt.Chart(df, width=350, height=300)\n",
    "        .mark_circle(stroke=\"white\", size=80, opacity=1)\n",
    "        .encode(x=spirals_x_axis, y=spirals_y_axis, color=alt.Color(\"label:N\"))\n",
    "    )\n",
    "\n",
    "    return spiral_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_plot(xs, y):\n",
    "    data = {\"x\": xs[:, 0], \"y\": xs[:, 1], \"pred\": np.exp(y)[:, 1]}\n",
    "    df = pd.DataFrame(data)\n",
    "    spirals_x_axis = alt.X(\"x\", scale=alt.Scale(domain=[-1.5, 1.5], nice=False))\n",
    "    spirals_y_axis = alt.Y(\"y\", scale=alt.Scale(domain=[-1.5, 1.5], nice=False))\n",
    "    pred_chart = (\n",
    "        alt.Chart(df, width=350, height=300, title=\"Predictions from MLP\")\n",
    "        .mark_square(size=50, opacity=1)\n",
    "        .encode(\n",
    "            x=spirals_x_axis,\n",
    "            y=spirals_y_axis,\n",
    "            color=alt.Color(\"pred\", scale=alt.Scale(scheme=\"blueorange\")),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return pred_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points, labels = make_spirals(dataset_size, noise_std=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spiral_chart = true_plot(points, labels)\n",
    "spiral_chart\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchModel(nn.Module):\n",
    "    def __init__(self, hidden_size: int, num_layers: int):\n",
    "        super(TorchModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Linear(2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            *(nn.Linear(hidden_size, hidden_size), nn.ReLU()) * (num_layers - 1),\n",
    "            nn.Linear(hidden_size, 2),\n",
    "            nn.LogSoftmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.stack(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create torch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_models = [TorchModel(hidden_size, num_layers) for _ in range(swarm_size)]\n",
    "torch_optimizers = [\n",
    "    torch.optim.Adam(torch_model.parameters(), lr=lr) for torch_model in torch_models\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set torch to use GPU if available\n",
    "device = torch.device(\"cpu\")\n",
    "if GPU and torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    for torch_model in torch_models:\n",
    "        torch_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to torch tensors\n",
    "X_train_torch = torch.from_numpy(np.array(points)).float()\n",
    "y_train_torch = torch.from_numpy(np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to GPU if available\n",
    "if GPU:\n",
    "    X_train_torch = X_train_torch.to(device)\n",
    "    y_train_torch = y_train_torch.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train torch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "k = 0\n",
    "for torch_model, torch_optimizer in zip(torch_models, torch_optimizers):\n",
    "    k += 1\n",
    "    torch_model.train()\n",
    "    for epoch in range(epochs):\n",
    "        torch_optimizer.zero_grad()\n",
    "        y_pred = torch_model(X_train_torch)\n",
    "        loss = torch.nn.functional.cross_entropy(y_pred, y_train_torch)\n",
    "        loss.backward()\n",
    "        torch_optimizer.step()\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Model {k} - Epoch {epoch} Loss: {loss.item()}\")\n",
    "\n",
    "print(f\"torch time: {time() - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize torch predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = pred_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take average of predictions across all models\n",
    "y = np.zeros((len(torch_models), xs.shape[0], 2))\n",
    "for idx, model in enumerate(torch_models):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(torch.from_numpy(xs).float().to(device))\n",
    "        y[idx] = y_pred.cpu().numpy()\n",
    "\n",
    "y = np.mean(y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions\n",
    "pred_chart = prediction_plot(xs, y)\n",
    "chart = pred_chart + spiral_chart\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_turba(params, input, output, apply_fn):\n",
    "    log_probs = apply_fn({\"params\": params}, input)\n",
    "    labels = jax.nn.one_hot(output, log_probs.shape[1])\n",
    "    loss = -jnp.mean(jnp.sum(labels * log_probs, axis=1))\n",
    "    return loss, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JaxModel(linen.Module):\n",
    "    hidden_layers: int = 1\n",
    "    hidden_dim: int = 32\n",
    "\n",
    "    @linen.compact\n",
    "    def __call__(self, x):\n",
    "        for layer in range(self.hidden_layers):\n",
    "            x = linen.Dense(self.hidden_dim)(x)\n",
    "            x = linen.relu(x)\n",
    "        x = linen.Dense(2)(x)\n",
    "        x = linen.log_softmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "optimizer = optax.adam(learning_rate=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Turba model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turba_model = JaxModel(hidden_layers=num_layers, hidden_dim=hidden_size)\n",
    "turba_state = TurbaTrainState.swarm(turba_model, optimizer, swarm_size, points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Turba to use GPU if available\n",
    "if GPU and xla_bridge.get_backend().platform != \"gpu\":\n",
    "    raise RuntimeError(\"GPU support not available for Turba.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Turba model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to jnp arrays\n",
    "X_train_turba = jnp.array(\n",
    "    np.expand_dims(points, axis=0).repeat(swarm_size, axis=0), dtype=jnp.float32\n",
    ")\n",
    "y_train_turba = jnp.array(np.expand_dims(labels, axis=0).repeat(swarm_size, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "for epoch in range(epochs):\n",
    "    turba_state, loss, _ = turba_state.train(X_train_turba, y_train_turba, cross_entropy_turba)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch} Loss: {loss.mean()}\")\n",
    "\n",
    "print(f\"turba time: {time() - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize turba predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = pred_grid()\n",
    "xs = jnp.array(np.expand_dims(xs, axis=0).repeat(swarm_size, axis=0), dtype=jnp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take average of predictions across all models\n",
    "y = turba_state.predict(xs)\n",
    "y = np.mean(y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy\n",
    "xs = np.array(xs[0])\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions\n",
    "pred_chart = prediction_plot(xs, y)\n",
    "chart = pred_chart + spiral_chart\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model functions\n",
    "classifier_fns = JaxModel(hidden_layers=num_layers, hidden_dim=hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "optimizer = optax.adam(learning_rate=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "def cross_entropy(logprobs, labels):\n",
    "    one_hot_labels = jax.nn.one_hot(labels, logprobs.shape[1])\n",
    "    return -jnp.mean(jnp.sum(one_hot_labels * logprobs, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create wrapper loss function and gradient\n",
    "def loss_fn(params, batch):\n",
    "    logits = classifier_fns.apply({\"params\": params}, batch[0])\n",
    "    loss = jnp.mean(cross_entropy(logits, batch[1]))\n",
    "    return loss\n",
    "\n",
    "\n",
    "loss_and_grad_fn = jax.value_and_grad(loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define initialization function\n",
    "def init_fn(input_shape, seed):\n",
    "    rng = jr.PRNGKey(seed)\n",
    "    dummy_input = jnp.ones((1, input_shape))\n",
    "    params = classifier_fns.init(rng, dummy_input)[\"params\"]\n",
    "    opt_state = optimizer.init(params)\n",
    "    return params, opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training function\n",
    "@jax.jit\n",
    "def train_step_fn(params, opt_state, batch):\n",
    "    loss, grad = loss_and_grad_fn(params, batch)\n",
    "    updates, opt_state = optimizer.update(grad, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, opt_state, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prediction function\n",
    "@jax.jit\n",
    "def predict_fn(params, x):\n",
    "    x = jnp.array(x)\n",
    "    return classifier_fns.apply({\"params\": params}, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vectorized functions\n",
    "parallel_init_fn = jax.vmap(init_fn, in_axes=(None, 0))\n",
    "parallel_train_step_fn = jax.vmap(train_step_fn, in_axes=(0, 0, None))\n",
    "parallel_predict_fn = jax.vmap(predict_fn, in_axes=(0, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Jax Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "seeds = jnp.linspace(0, swarm_size - 1, swarm_size).astype(int)\n",
    "model_states, opt_states = parallel_init_fn(2, seeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Jax model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "start = time()\n",
    "for i in range(epochs):\n",
    "    model_states, opt_states, _ = parallel_train_step_fn(\n",
    "        model_states, opt_states, (points, labels)\n",
    "    )\n",
    "\n",
    "print(f\"jax time: {time() - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize jax predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prediction grid\n",
    "xs = jnp.array(pred_grid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take average of predictions across all models\n",
    "y = parallel_predict_fn(model_states, xs)\n",
    "y = jnp.mean(y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy\n",
    "xs = np.array(xs)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions\n",
    "pred_chart = prediction_plot(xs, y)\n",
    "chart = pred_chart + spiral_chart\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
